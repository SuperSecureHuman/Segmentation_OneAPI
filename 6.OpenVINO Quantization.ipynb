{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx, openvino\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics as tm\n",
    "from typing import Union\n",
    "from openvino.runtime.ie_api import CompiledModel\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from openvino.tools import mo\n",
    "from openvino.runtime import serialize\n",
    "\n",
    "import torch\n",
    "import nncf\n",
    "from openvino.runtime import Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"./model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetModel(nn.Module):\n",
    "    def __init__(self, arch, encoder_name, in_channels, out_classes, **kwargs):\n",
    "        super().__init__()\n",
    "        self.model = smp.create_model(\n",
    "            arch, encoder_name=encoder_name, in_channels=in_channels, classes=out_classes, **kwargs\n",
    "        )\n",
    "\n",
    "        params = smp.encoders.get_preprocessing_params(encoder_name)\n",
    "        self.std = torch.tensor(params[\"std\"]).view(1, 3, 1, 1)\n",
    "        self.mean = torch.tensor(params[\"mean\"]).view(1, 3, 1, 1)\n",
    "        self.loss_fn = smp.losses.DiceLoss(\n",
    "            smp.losses.BINARY_MODE, from_logits=True)\n",
    "\n",
    "    def forward(self, image):\n",
    "        image = (image - self.mean) / self.std\n",
    "        mask = self.model(image)\n",
    "        return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./model/model.pth\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader = give_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice(model: Union[torch.nn.Module, CompiledModel], dataset):\n",
    "    metric = tm.Dice(zero_division = 0, num_classes = 2)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataset, total = len(dataset)):\n",
    "            image = batch[\"image\"]\n",
    "            target = batch[\"mask\"]\n",
    "            input_image = torch.as_tensor(image) #.unsqueeze(0)\n",
    "            if isinstance(model, CompiledModel):\n",
    "                output_layer = model.output(0)\n",
    "                output = model(input_image)[output_layer]\n",
    "                output = torch.from_numpy(output)\n",
    "            else:\n",
    "                output = model(input_image)\n",
    "            label = torch.as_tensor(target.squeeze()).long()\n",
    "            prediction = torch.sigmoid(output.squeeze()).round().long()\n",
    "            metric.update(label.flatten(), prediction.flatten())\n",
    "    return metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [03:37<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP32 Dice: 0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fp32_dice = compute_dice(model, test_dataloader)\n",
    "print(f\"FP32 Dice: {fp32_dice:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venom/miniconda3/lib/python3.9/site-packages/intel_extension_for_pytorch/frontend.py:474: UserWarning: Conv BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\"Conv BatchNorm folding failed during the optimize process.\")\n",
      "/home/venom/miniconda3/lib/python3.9/site-packages/intel_extension_for_pytorch/frontend.py:479: UserWarning: Linear BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\"Linear BatchNorm folding failed during the optimize process.\")\n",
      "/home/venom/miniconda3/lib/python3.9/site-packages/segmentation_models_pytorch/base/model.py:16: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if h % output_stride != 0 or w % output_stride != 0:\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save model onnx\n",
    "torch.onnx.export(model, batch['image'], \"model.onnx\", export_params=True, opset_version=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai/2023.0/openvino_2_0_transition_guide.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/venom/repo/Segmentation_OneAPI/model.xml\n",
      "[ SUCCESS ] BIN file: /home/venom/repo/Segmentation_OneAPI/model.bin\n"
     ]
    }
   ],
   "source": [
    "!mo --input_model ./model/model.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_fn(data_item):\n",
    "    \"\"\"\n",
    "    Extract the model's input from the data item.\n",
    "    The data item here is the data item that is returned from the data source per iteration.\n",
    "    This function should be passed when the data item cannot be used as model's input.\n",
    "    \"\"\"\n",
    "    images = data_item[\"image\"]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:nncf:NNCF provides best results with torch==1.13.1, while current torch version is 2.0.1+cu117. If you encounter issues, consider switching to torch==1.13.1\n",
      "INFO:nncf:Collecting tensor statistics |█               | 33 / 300\n",
      "INFO:nncf:Collecting tensor statistics |███             | 66 / 300\n",
      "INFO:nncf:Collecting tensor statistics |█████           | 99 / 300\n",
      "INFO:nncf:Collecting tensor statistics |███████         | 132 / 300\n",
      "INFO:nncf:Collecting tensor statistics |████████        | 165 / 300\n",
      "INFO:nncf:Collecting tensor statistics |██████████      | 198 / 300\n",
      "INFO:nncf:Collecting tensor statistics |████████████    | 231 / 300\n",
      "INFO:nncf:Collecting tensor statistics |██████████████  | 264 / 300\n",
      "INFO:nncf:Collecting tensor statistics |███████████████ | 297 / 300\n",
      "INFO:nncf:Collecting tensor statistics |████████████████| 300 / 300\n",
      "INFO:nncf:Compiling and loading torch extension: quantized_functions_cpu...\n",
      "INFO:nncf:Finished loading torch extension: quantized_functions_cpu\n",
      "INFO:nncf:BatchNorm statistics adaptation |█               | 33 / 300\n",
      "INFO:nncf:BatchNorm statistics adaptation |███             | 66 / 300\n",
      "INFO:nncf:BatchNorm statistics adaptation |█████           | 99 / 300\n",
      "INFO:nncf:BatchNorm statistics adaptation |███████         | 132 / 300\n",
      "INFO:nncf:BatchNorm statistics adaptation |████████        | 165 / 300\n",
      "INFO:nncf:BatchNorm statistics adaptation |██████████      | 198 / 300\n",
      "INFO:nncf:BatchNorm statistics adaptation |████████████    | 231 / 300\n",
      "INFO:nncf:BatchNorm statistics adaptation |██████████████  | 264 / 300\n",
      "INFO:nncf:BatchNorm statistics adaptation |███████████████ | 297 / 300\n",
      "INFO:nncf:BatchNorm statistics adaptation |████████████████| 300 / 300\n"
     ]
    }
   ],
   "source": [
    "calibration_dataset = nncf.Dataset(valid_dataloader, transform_fn)\n",
    "quantized_model = nncf.quantize(\n",
    "    model,\n",
    "    calibration_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 3, 256, 256)\n",
    "int8_onnx_path = f\"{MODEL_DIR}model_int8.onnx\"\n",
    "int8_ir_path = Path(int8_onnx_path).with_suffix(\".xml\")\n",
    "torch.onnx.export(quantized_model, dummy_input, int8_onnx_path)\n",
    "int8_ir_model = mo.convert_model(input_model=int8_onnx_path)\n",
    "serialize(int8_ir_model, str(int8_ir_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [01:14<00:00, 49.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INT8 F1: 0.950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "core = Core()\n",
    "\n",
    "int8_compiled_model = core.compile_model(int8_ir_model)\n",
    "int8_die = compute_dice(int8_compiled_model, test_dataloader)\n",
    "\n",
    "print(f\"INT8 Dice: {int8_die:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
