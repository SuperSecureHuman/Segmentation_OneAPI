{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 13:47:54,735 - torch.distributed.nn.jit.instantiator - INFO - Created a temporary directory at /tmp/tmp_l0wbt0m\n",
      "2023-08-13 13:47:54,737 - torch.distributed.nn.jit.instantiator - INFO - Writing /tmp/tmp_l0wbt0m/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-13 13:47:54,939] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cpu (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 13:48:03.227119: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-13 13:48:03.461218: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "import time\n",
    "import cv2\n",
    "import intel_extension_for_pytorch as ipex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetModel(nn.Module):\n",
    "    def __init__(self, arch, encoder_name, in_channels, out_classes, **kwargs):\n",
    "        super().__init__()\n",
    "        self.model = smp.create_model(\n",
    "            arch, encoder_name=encoder_name, in_channels=in_channels, classes=out_classes, **kwargs\n",
    "        )\n",
    "\n",
    "        params = smp.encoders.get_preprocessing_params(encoder_name)\n",
    "        self.std = torch.tensor(params[\"std\"]).view(1, 3, 1, 1)\n",
    "        self.mean = torch.tensor(params[\"mean\"]).view(1, 3, 1, 1)\n",
    "        self.loss_fn = smp.losses.DiceLoss(\n",
    "            smp.losses.BINARY_MODE, from_logits=True)\n",
    "\n",
    "    def forward(self, image):\n",
    "        image = (image - self.mean) / self.std\n",
    "        mask = self.model(image)\n",
    "        return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./model/model.pth\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venom/miniconda3/lib/python3.9/site-packages/segmentation_models_pytorch/base/model.py:16: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if h % output_stride != 0 or w % output_stride != 0:\n"
     ]
    }
   ],
   "source": [
    "# torchscript the model in fp16 mode\n",
    "model.eval()\n",
    "example = torch.rand(1, 3, 512, 256).half()\n",
    "model = torch.jit.trace(model, example)\n",
    "model = torch.jit.freeze(model)\n",
    "model = ipex.optimize(model, dtype=torch.float16, level=\"O3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (256, 256))\n",
    "    frame_org = frame\n",
    "    frame = torch.from_numpy(frame).float().permute(2, 0, 1).unsqueeze(0)\n",
    "    return frame\n",
    "\n",
    "def perform_inference(model, frame):\n",
    "    inference_start_time = time.time()\n",
    "    mask = model(frame.half())\n",
    "    mask = torch.sigmoid(mask)\n",
    "    mask = mask.float().squeeze().detach().numpy()\n",
    "    inference_time = time.time() - inference_start_time\n",
    "    return mask, inference_time\n",
    "\n",
    "def postprocess_frame(mask):\n",
    "    # Add any additional post-processing steps here if needed\n",
    "    post_processing_time = 0  # Placeholder, as there are no explicit post-processing steps\n",
    "    return post_processing_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 16.12, Frame Time: 62.02 ms, Preprocessing Time: 0.00 s, Inference Time: 0.06 s, Post-processing Time: 0.00 s\r"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"./cat.mp4\")\n",
    "while True:\n",
    "    # Record the start time before processing each frame\n",
    "    start_time = time.time()\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Preprocessing\n",
    "        preprocessing_start_time = time.time()\n",
    "        frame = preprocess_frame(frame)\n",
    "        preprocessing_time = time.time() - preprocessing_start_time\n",
    "        # Inference\n",
    "        mask, inference_time = perform_inference(model, frame)\n",
    "        # Post-processing\n",
    "        post_processing_time = postprocess_frame(mask)\n",
    "        # Calculate FPS and frame time\n",
    "        total_time = time.time() - start_time\n",
    "        fps = 1.0 / total_time\n",
    "        frame_time = total_time * 1000.0  # Convert to milliseconds\n",
    "        # Print FPS and frame time\n",
    "        print(f\"FPS: {fps:.2f}, Frame Time: {frame_time:.2f} ms, \"\n",
    "              f\"Preprocessing Time: {preprocessing_time:.2f} s, \"\n",
    "              f\"Inference Time: {inference_time:.2f} s, \"\n",
    "              f\"Post-processing Time: {post_processing_time:.2f} s\", end=\"\\r\")\n",
    "        # Display the processed frame (mask) if you need to\n",
    "        cv2.imshow('mask', mask)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
