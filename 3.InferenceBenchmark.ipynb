{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare various naive methods of optmizing inference speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable cuda\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.datasets import SimpleOxfordPetDataset\n",
    "\n",
    "import timeit\n",
    "\n",
    "root = \".\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3312\n",
      "Valid size: 368\n",
      "Test size: 3669\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SimpleOxfordPetDataset(root, \"train\")\n",
    "valid_dataset = SimpleOxfordPetDataset(root, \"valid\")\n",
    "test_dataset = SimpleOxfordPetDataset(root, \"test\")\n",
    "\n",
    "# It is a good practice to check datasets don`t intersects with each other\n",
    "assert set(test_dataset.filenames).isdisjoint(set(train_dataset.filenames))\n",
    "assert set(test_dataset.filenames).isdisjoint(set(valid_dataset.filenames))\n",
    "assert set(train_dataset.filenames).isdisjoint(set(valid_dataset.filenames))\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Valid size: {len(valid_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")\n",
    "\n",
    "n_cpu = os.cpu_count()\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=16, shuffle=True, num_workers=n_cpu)\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset, batch_size=16, shuffle=False, num_workers=n_cpu)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=16, shuffle=False, num_workers=n_cpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetModel(nn.Module):\n",
    "    def __init__(self, arch, encoder_name, in_channels, out_classes, **kwargs):\n",
    "        super().__init__()\n",
    "        self.model = smp.create_model(\n",
    "            arch, encoder_name=encoder_name, in_channels=in_channels, classes=out_classes, **kwargs\n",
    "        )\n",
    "\n",
    "        params = smp.encoders.get_preprocessing_params(encoder_name)\n",
    "        self.std = torch.tensor(params[\"std\"]).view(1, 3, 1, 1)\n",
    "        self.mean = torch.tensor(params[\"mean\"]).view(1, 3, 1, 1)\n",
    "        self.loss_fn = smp.losses.DiceLoss(\n",
    "            smp.losses.BINARY_MODE, from_logits=True)\n",
    "\n",
    "    def forward(self, image):\n",
    "        image = (image - self.mean) / self.std\n",
    "        mask = self.model(image)\n",
    "        return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"FPN\"\n",
    "encoder_name = \"resnet34\"\n",
    "in_channels = 3\n",
    "out_classes = 1\n",
    "model = PetModel(arch, encoder_name, in_channels, out_classes)\n",
    "criterion = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take one batch from valid dataloader\n",
    "batch = next(iter(valid_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3, 256, 256]), torch.Size([16, 1, 256, 256]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['image'].shape, batch['mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        return model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup time - Batch 16: 1.1051 s\n"
     ]
    }
   ],
   "source": [
    "time = timeit.timeit(lambda: benchmark(model, batch['image']), number=1)\n",
    "print(f\"warmup time - Batch 16: {time:.4f} s\")\n",
    "time = timeit.timeit(lambda: benchmark(model, batch['image']), number=10)\n",
    "print(f\"benchmark time: {time:.4f} s\")\n",
    "time = timeit.timeit(lambda: benchmark(\n",
    "    model, batch['image'][0].unsqueeze(0)), number=1)\n",
    "print(f\"warmup time - Batch 1: {time:.4f} s\")\n",
    "\n",
    "time = timeit.timeit(lambda: benchmark(\n",
    "    model, batch['image'][0].unsqueeze(0)), number=10)\n",
    "print(f\"benchmark time (Batch 1): {time:.4f} s\")\n",
    "time = time/10\n",
    "print(f\"Per Iter time(Batch 1): {time:.4f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intel_extension_for_pytorch as ipex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPEX - Float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venom/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/intel_extension_for_pytorch/frontend.py:522: UserWarning: Conv BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\"Conv BatchNorm folding failed during the optimize process.\")\n",
      "/home/venom/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/intel_extension_for_pytorch/frontend.py:527: UserWarning: Linear BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\"Linear BatchNorm folding failed during the optimize process.\")\n"
     ]
    }
   ],
   "source": [
    "model = ipex.optimize(model, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup time - Batch 16: 0.6036 s\n",
      "benchmark time (Batch 16): 6.6450 s\n",
      "Per Iter time(Batch 16): 0.6645 s\n",
      "warmup time - Batch 1: 0.0394 s\n",
      "benchmark time (Batch 1): 0.3884 s\n",
      "Per Iter time(Batch 1): 0.0388 s\n"
     ]
    }
   ],
   "source": [
    "time = timeit.timeit(lambda: benchmark(model, batch['image']), number=1)\n",
    "print(f\"warmup time - Batch 16: {time:.4f} s\")\n",
    "time = timeit.timeit(lambda: benchmark(model, batch['image']), number=10)\n",
    "print(f\"benchmark time (Batch 16): {time:.4f} s\")\n",
    "time = time/10\n",
    "print(f\"Per Iter time(Batch 16): {time:.4f} s\")\n",
    "time = timeit.timeit(lambda: benchmark(\n",
    "    model, batch['image'][0].unsqueeze(0)), number=1)\n",
    "print(f\"warmup time - Batch 1: {time:.4f} s\")\n",
    "\n",
    "time = timeit.timeit(lambda: benchmark(\n",
    "    model, batch['image'][0].unsqueeze(0)), number=10)\n",
    "print(f\"benchmark time (Batch 1): {time:.4f} s\")\n",
    "time = time/10\n",
    "print(f\"Per Iter time(Batch 1): {time:.4f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPEX - BFloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venom/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/intel_extension_for_pytorch/frontend.py:522: UserWarning: Conv BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\"Conv BatchNorm folding failed during the optimize process.\")\n",
      "/home/venom/intel/oneapi/intelpython/latest/envs/pytorch/lib/python3.9/site-packages/intel_extension_for_pytorch/frontend.py:527: UserWarning: Linear BatchNorm folding failed during the optimize process.\n",
      "  warnings.warn(\"Linear BatchNorm folding failed during the optimize process.\")\n"
     ]
    }
   ],
   "source": [
    "model = PetModel(arch, encoder_name, in_channels, out_classes)\n",
    "model.eval()\n",
    "model = ipex.optimize(model, dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup time - Batch 16: 0.7158 s\n",
      "benchmark time (Batch 16): 6.3737 s\n",
      "Per Iter time(Batch 16): 0.6374 s\n",
      "warmup time - Batch 1: 0.0379 s\n",
      "benchmark time (Batch 1): 0.4146 s\n",
      "Per Iter time(Batch 1): 0.0415 s\n"
     ]
    }
   ],
   "source": [
    "time = timeit.timeit(lambda: benchmark(model, batch['image']), number=1)\n",
    "print(f\"warmup time - Batch 16: {time:.4f} s\")\n",
    "time = timeit.timeit(lambda: benchmark(model, batch['image']), number=10)\n",
    "print(f\"benchmark time (Batch 16): {time:.4f} s\")\n",
    "time = time/10\n",
    "print(f\"Per Iter time(Batch 16): {time:.4f} s\")\n",
    "\n",
    "time = timeit.timeit(lambda: benchmark(\n",
    "    model, batch['image'][0].unsqueeze(0)), number=1)\n",
    "print(f\"warmup time - Batch 1: {time:.4f} s\")\n",
    "time = timeit.timeit(lambda: benchmark(\n",
    "    model, batch['image'][0].unsqueeze(0)), number=10)\n",
    "print(f\"benchmark time (Batch 1): {time:.4f} s\")\n",
    "time = time/10\n",
    "print(f\"Per Iter time(Batch 1): {time:.4f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference - TorchScript Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PetModel(arch, encoder_name, in_channels, out_classes).eval()\n",
    "model = ipex.optimize(model, dtype=torch.float32)\n",
    "model = torch.jit.trace(model, batch['image'])\n",
    "model = torch.jit.freeze(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup time - Batch 16: 0.5830 s\n",
      "benchmark time (Batch 16): 4.4572 s\n",
      "Per Iter time(Batch 16): 0.4457 s\n"
     ]
    }
   ],
   "source": [
    "time = timeit.timeit(lambda: benchmark(model, batch['image']), number=1)\n",
    "print(f\"warmup time - Batch 16: {time:.4f} s\")\n",
    "time = timeit.timeit(lambda: benchmark(model, batch['image']), number=10)\n",
    "print(f\"benchmark time (Batch 16): {time:.4f} s\")\n",
    "time = time/10\n",
    "print(f\"Per Iter time(Batch 16): {time:.4f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PetModel(arch, encoder_name, in_channels, out_classes).eval()\n",
    "model = ipex.optimize(model, dtype=torch.float32)\n",
    "model = torch.jit.trace(model, batch['image'][0].unsqueeze(0))\n",
    "model = torch.jit.freeze(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup time - Batch 1: 0.1001 s\n",
      "benchmark time (Batch 1): 0.5284 s\n",
      "Per Iter time(Batch 1): 0.0528 s\n"
     ]
    }
   ],
   "source": [
    "time = timeit.timeit(lambda: benchmark(\n",
    "    model, batch['image'][0].unsqueeze(0)), number=1)\n",
    "print(f\"warmup time - Batch 1: {time:.4f} s\")\n",
    "time = timeit.timeit(lambda: benchmark(\n",
    "    model, batch['image'][0].unsqueeze(0)), number=10)\n",
    "print(f\"benchmark time (Batch 1): {time:.4f} s\")\n",
    "time = time/10\n",
    "print(f\"Per Iter time(Batch 1): {time:.4f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
